"""
æ­¤æ¨¡å—ç”¨äºåˆå§‹åŒ– RAG å¼•æ“ã€‚

å®ƒä¼šè®¾ç½®è¯­è¨€æ¨¡å‹ã€åµŒå…¥æ¨¡å‹ã€é‡æ’åºå™¨å’Œå‘é‡å­˜å‚¨ã€‚
å®ƒä½¿ç”¨ Ollama ä½œä¸ºå¤§å‹è¯­è¨€æ¨¡å‹å’ŒåµŒå…¥æ¨¡å‹ï¼Œå¹¶ä½¿ç”¨æœ¬åœ°çš„ SentenceTransformer
è¿›è¡Œé‡æ’åºã€‚å‘é‡å­˜å‚¨ä½¿ç”¨å¸¦æœ‰ pgvector æ‰©å±•çš„ PostgreSQL æ•°æ®åº“ã€‚

Author: Guo Lijian
"""
import os
from llama_index.core import VectorStoreIndex, StorageContext
from llama_index.embeddings.ollama import OllamaEmbedding
from llama_index.vector_stores.postgres import PGVectorStore
from llama_index.core import Settings
from llama_index.llms.ollama import Ollama
from llama_index.core.postprocessor import SentenceTransformerRerank

DB_NAME = os.getenv("DB_NAME", "knowledge_base")
DB_HOST = os.getenv("DB_HOST", "localhost")
DB_PASS = os.getenv("DB_PASSWORD", "admin_password")
DB_PORT = os.getenv("DB_PORT", "5432")
DB_USER = os.getenv("DB_USER", "admin")
EMBED_DIM = int(os.getenv("EMBEDDING_DIM", 1024))
OLLAMA_BASE_URL = os.getenv("OLLAMA_BASE_URL", "http://localhost:11434")
LLM_MODEL_NAME = os.getenv("LLM_MODEL_NAME", "qwen2.5:3b")
EMBED_MODEL_NAME = os.getenv("EMBED_MODEL_NAME", "BGE-M3") # BGE-M3 æ¯”è¾ƒå¤§æ•ˆæœæ›´å¥½ä½†æ˜¯å¾ˆæ…¢ï¼Œå¦‚æœå«Œæ…¢å¯ä»¥è®¾ç½®æˆnomic-embed-text


def init_settings():
    # ç»™å®ƒåŠ ä¸ª keep_aliveï¼Œè®©å®ƒèŠå®Œåˆ«æ€¥ç€é€€å‡ºï¼Œé¿å…ä¸‹æ¬¡èŠå¤©åˆè¦åŠ è½½
    print(f"âš™ï¸ è¿æ¥ Ollama LLM æ¨¡å‹: {LLM_MODEL_NAME}...")
    Settings.llm = Ollama(
        model=LLM_MODEL_NAME,
        base_url=OLLAMA_BASE_URL,
        request_timeout=300.0,
        context_window=4096,
        keep_alive="1h", # è¿™é‡Œä¹Ÿè®¾ç½®ä¸€éï¼ŒåŒé‡ä¿é™©
        additional_kwargs={"keep_alive": "1h"} # å…¼å®¹ä¸åŒç‰ˆæœ¬å‚æ•°åç§°
    )
    print("âœ… LLM æ¨¡å‹è¿æ¥é…ç½®å®Œæˆ")
    # Embedding æ¨¡å‹åŠ è½½
    print(f"âš™ï¸ è¿æ¥ Ollama Embedding æ¨¡å‹: {EMBED_MODEL_NAME}...")
    Settings.embed_model = OllamaEmbedding(
        model_name=EMBED_MODEL_NAME,
        base_url=OLLAMA_BASE_URL,
        request_timeout=300.0,
        embed_batch_size=10
    )
    print("âœ… Embedding æ¨¡å‹è¿æ¥é…ç½®å®Œæˆ")


# 2. Reranker å•ä¾‹
_reranker = None


def get_reranker():
    global _reranker
    if _reranker is None:
        print("â³ æ­£åœ¨åŠ è½½æœ¬åœ° Reranker æ¨¡å‹: bge-reranker-base...")
        model_path = "./models/bge-reranker-base"

        if not os.path.exists(model_path):
            # å…¼å®¹ Docker è·¯å¾„æˆ–æœ¬åœ°è·¯å¾„
            if os.path.exists("/app/models/bge-reranker-base"):
                model_path = "/app/models/bge-reranker-base"
            else:
                raise RuntimeError(f"âŒ æ‰¾ä¸åˆ°æœ¬åœ°æ¨¡å‹æ–‡ä»¶: {model_path}ï¼Œè¯·å…ˆä¸‹è½½ï¼")

        _reranker = SentenceTransformerRerank(
            model=model_path,
            top_n=5
        )
        print("âœ… æœ¬åœ° Reranker æ¨¡å‹åŠ è½½å®Œæˆ")
    return _reranker

# 3. Index è·å–å‡½æ•°
_vector_index_instance = None

def get_vector_index():
    global _vector_index_instance

    # 2. å¦‚æœå·²ç»åˆå§‹åŒ–è¿‡ï¼Œç›´æ¥è¿”å›ï¼Œä¸å†åˆ›å»º
    if _vector_index_instance is not None:
        return _vector_index_instance

    print("ğŸ”Œ æ­£åœ¨åˆå§‹åŒ–å‘é‡æ•°æ®åº“è¿æ¥...")

    # 3. åˆå§‹åŒ–é€»è¾‘ (ä¿æŒä¸å˜)
    vector_store = PGVectorStore.from_params(
        database=DB_NAME,
        host=DB_HOST,
        password=DB_PASS,
        port=DB_PORT,
        user=DB_USER,
        table_name="embeddings",
        embed_dim=EMBED_DIM
    )
    storage_context = StorageContext.from_defaults(vector_store=vector_store)

    # 4. åˆ›å»ºå®ä¾‹å¹¶èµ‹å€¼ç»™å…¨å±€å˜é‡
    _vector_index_instance = VectorStoreIndex.from_vector_store(
        vector_store=vector_store,
        storage_context=storage_context
    )

    print("âœ… å‘é‡ç´¢å¼•åŠ è½½å®Œæˆ (Singleton)")
    return _vector_index_instance